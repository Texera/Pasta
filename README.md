<h1 align="center">Pasta: A Cost-Based Optimizer for Generating Pipelining Schedules for Dataflow DAGs</h1>


This repo contains the source code and data for Pasta ([SIGMOD'25 Paper](https://dl.acm.org/doi/10.1145/3698832)).

<img src="core/gui/src/assets/logos/full_logo_small.png" alt="texera-logo" width="25px" height="50px"/> Pasta is built on top of Apache Texera (Incubating), a collaborative data analytics workflow system.

The experiments in the paper were performed on a branch of Texera in July 2024. Since then the Pasta scheduler has been fully integrated into Texera's master and we have moved the additional source code related to running Pasta's experiments to this repo (forked from Texera on August 2025).

# Running Experiments

## Setting up Texera

Follow https://github.com/apache/texera/wiki/Guide-for-Developers to setup a dev environment for Texera and run the backend micro services in IntelliJ. For the step of "Clone and Configure Texera", use this link instead:

```
git clone git@github.com:Texera/pasta.git
```

## Running Experiments Related to Goal 1: Minimizing Total Sizes of Materialization

All the workflows we used for analyses and running experiments on the optimization goal of minimizing total sizes of materialization are in the following file:

```
/pasta_experiment_inputs/wallclock_runtime_experiment_workflows.zip
```

Extract this file in the same directory. It contains ~6K real-world workflows as Texera workflow source files. Note the workflows are only used for analysis and simulating scheduling optimization on the goal of reducing materialzation sizes, and will not be executable in Texera.

To run a complete set of experiments for Goal 1, navigate to this file in Intellij:

```
core/amber/src/main/scala/edu/uci/ics/texera/workflow/PastaMatSizeOptimizationExperimentRunner.scala
```

Execute `PastaMatSizeOptimizationExperimentRunner` in Intellij and provide 3 CLI arguments to this binary:

`<input_file> <output_directory> <results_file>`

- <input_file>: The path to the source of a workflow, e.g., `".../pasta_experiment_inputs/mat_size_experiment_workflows/_01_ChemicalLibraryEnumeration.json"`
- <output_directory>: Your desired path to the additional output files to be generated by the experiment runner. These will be images of the input physical plan and region plans of each method.
- <results_file>: Your desired path of the result CSV file. The complete statistics about the input workflow and the performance of each method on this workflow will be written to this CSV file.

## Running Experiments Related to Goal 2: Minimizing Workflow Wall-clock Runtime

The workflows and their input files of this goal can be found in 

```
/pasta_experiment_inputs/mat_size_experiment_workflows.zip
```

Extract this file in the same directory. There are two executable Texera workflows for this experiment.

This step requires running Texera. Once you have set up a dev Texera environment (including Community features) and have Texera running locally, follow these additional steps to run experiments for each workflow:

- In "Your Work" -> "Datasets", Create a new dataset for the workflow.

<img width="204" height="107" alt="image" src="https://github.com/user-attachments/assets/d78404e2-bc95-4b7c-898e-9017d1467980" />

- Navigate to the newly-created dataset, and upload the input file to this data set. Click "Submit" in the end and leave the dataset version to be the default.
<img width="935" height="682" alt="image" src="https://github.com/user-attachments/assets/f102a2aa-0b61-4357-988f-a7d5e4f542da" />

- In "Your Work" -> "Workflows", upload the workflow JSON to Texera
<img width="421" height="159" alt="image" src="https://github.com/user-attachments/assets/1150f5f5-5725-42eb-8b87-f81b5ab8da9b" />

- Open the uploaded workflow:
<img width="2552" height="1283" alt="image" src="https://github.com/user-attachments/assets/8dfbb0aa-d39f-4e84-a1a6-463fd5e36ce6" />

- Click the "CSV File Scan" operator and replace its "File" property with you uploaded file (click "Reselect File" and choose from the newly created dataset)
<img width="967" height="394" alt="image" src="https://github.com/user-attachments/assets/416eea5e-9c77-41a1-96d8-de8b1357ccd2" />

- Again on "CSV File Scan" operator operator, change the "Limit" to be the desired input data size (e.g., 1000)

- Hover on the "Run" button and input the execution name to be one of the following:
```
ALL_MAT
BASELINE
TOP_DOWN_GLOBAL
BOTTOM_UP_GLOBAL
TOP_DOWN_GREEDY
BOTTOM_UP_GREEDY
```
The execution name is used to indicate to the scheduler which method to use.

<img width="211" height="169" alt="image" src="https://github.com/user-attachments/assets/376cdffb-c0d0-4413-9d1a-04c12f5aa2ec" />

- Click on "Run" to execute the workflow.

- Note: Before running any experiment, always run "ALL_MAT" once and let the execution finish so that there is some past statistics to be used by the scheduler for calculating costs.

- The details of the scheduling performance will be output as a console log, and the totol wall-clock runtime of this workflow can be viewed on the frontend: <img width="236" height="38" alt="image" src="https://github.com/user-attachments/assets/73c29582-d465-4a07-b33a-cf4f1291b37f" />

- When testing different input file sizes, it is recommended to create a new workflow for each input size so that their respective cost information can be measured accurately.


## Acknowledgements

This project is supported by the <a href="http://www.nsf.gov">National Science Foundation</a> under the award [IIS-2107150](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2107150).

* <a href="https://www.niddk.nih.gov/"><img src="https://github.com/Texera/texera/assets/17627829/d279897a-3efb-41c1-b2d3-8fd20c800ad7" alt="NIH NIDDK" height="30"/></a> This project is supported by an <a href="https://reporter.nih.gov/project-details/10818244">NIH NIDDK</a> award.
